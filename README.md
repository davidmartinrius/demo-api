# üìö FastAPI¬†+ LangChain RAG Demo (gpt4free edition)

A lightweight **retrieval‚Äëaugmented generation (RAG)** micro‚Äëservice you can run on any laptop (CPU‚Äëonly) or deploy cheaply to **Google¬†Cloud¬†Run**‚Äîwith **no LLM API key** required.  
It embeds your local documents with **sentence‚Äëtransformers**, stores them in **FAISS**, retrieves the most relevant chunks, and asks **gpt4free** (GPT‚Äë4‚Äëclass) to craft an answer.

---

## ‚ú® Stack at a glance

| Layer | Component |
|-------|-----------|
| **LLM**        | *gpt4free* (auto‚Äëselects a live GPT‚Äë4 endpoint) |
| **Embeddings** | `sentence‚Äëtransformers/all‚ÄëMiniLM‚ÄëL6‚Äëv2` |
| **Vector¬†DB**  | FAISS (persisted on disk) |
| **Frameworks** | FastAPI ¬∑ LangChain |
| **Docs folder**| `./documents/` (next to `rag_demo_fastapi.py`) |

Default knobs: **chunk¬†=¬†800¬†chars**, **top‚Äëk¬†=¬†8**, **max_tokens¬†=¬†256** ‚Äì all configurable at the top of the script.

---

## üöÄ Quick¬†start (local)

```bash
# 1 ‚Äì¬†(optional) create a virtual‚Äëenv
python -m venv .venv && source .venv/bin/activate

# 2 ‚Äì install dependencies
yes | pip install --upgrade pip
pip install "fastapi[all]" uvicorn sentence-transformers langchain langchain-community
pip install --no-binary :all: g4f --upgrade   # g4f sometimes needs --no-binary

# 3 ‚Äì run the API with auto‚Äëreload
python -m uvicorn rag_demo_fastapi:app --reload --port 8080
```

Drop **`.pdf`, `.txt`, `.md` ‚Ä¶** into **`./documents/`** and the server will auto‚Äëreload and re‚Äëindex them.

---

## üîó Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `GET`  | `/generate?prompt=‚Ä¶`  | Raw chat completion via *gpt4free* |
| `GET`  | `/rag?question=‚Ä¶`    | Retrieval‚Äëaugmented answer sourced from your docs |
| `GET`  | `/ingested_docs`     | JSON preview of the indexed documents |

Examples:

```bash
curl "http://localhost:8080/generate?prompt=Hello%2C+who+are+you%3F"

curl "http://localhost:8080/rag?question=Which+programming+languages+are+mentioned%3F"
```

---

## ‚òÅÔ∏è¬†Deploy to Google¬†Cloud¬†Run (step‚Äëby‚Äëstep)

> These commands create a brand‚Äënew project, link billing, set a spending cap, build the image with Cloud¬†Build, push to Artifact¬†Registry, and deploy to Cloud¬†Run.

```bash
# 0¬†‚Äì choose IDs up front ------------------------------------------------------
export PROJECT_ID="your-project-$(date +%s)"   # e.g. drius-ai-run-1718123456
export REGION="europe-west1"                   # pick any Cloud¬†Run region

# 1¬†‚Äì list billing accounts and pick one --------------------------------------
gcloud beta billing accounts list
export BILLING_ID="0123A4-B5C6D7-89EF01"       # replace with your account ID

# 2¬†‚Äì create & link the project ----------------------------------------------
gcloud projects create $PROJECT_ID --name="rag-demo"
gcloud beta billing projects link $PROJECT_ID \
  --billing-account=$BILLING_ID

# 3¬†‚Äì (optional) set a budget so you never overspend --------------------------
gcloud beta billing budgets create \
  --billing-account=$BILLING_ID \
  --display-name="demo-limit" \
  --budget-amount=5EUR

# 4¬†‚Äì enable required services ------------------------------------------------
gcloud services enable \
  run.googleapis.com \
  artifactregistry.googleapis.com \
  cloudbuild.googleapis.com \
  logging.googleapis.com \
  monitoring.googleapis.com

# 5¬†‚Äì configure gcloud defaults ----------------------------------------------
gcloud config set project $PROJECT_ID
gcloud config set run/region $REGION

# 6¬†‚Äì create an Artifact¬†Registry repo (once) ---------------------------------
gcloud artifacts repositories create rag-demo-repo \
  --repository-format=docker \
  --location=$REGION

# 7¬†‚Äì build & push the container ---------------------------------------------
gcloud builds submit \
  --tag $REGION-docker.pkg.dev/$PROJECT_ID/rag-demo-repo/rag-demo:latest

# 8¬†‚Äì deploy to Cloud¬†Run ------------------------------------------------------
gcloud run deploy rag-demo \
  --image=$REGION-docker.pkg.dev/$PROJECT_ID/rag-demo-repo/rag-demo:latest \
  --region=$REGION \
  --platform=managed \
  --memory=1Gi \
  --min-instances=0 \
  --max-instances=3 \
  --allow-unauthenticated

# 9¬†‚Äì grab the HTTPS URL -------------------------------------------------------
gcloud run services describe rag-demo --region=$REGION --format="value(status.url)"
```

**What each step does**

| Step | Purpose |
|------|---------|
| 0‚Äë1 | Pick names & billing account. |
| 2   | Creates a new GCP project and links billing. |
| 3   | Sets a hard budget cap (optional but recommended). |
| 4   | Enables Cloud¬†Run, Cloud¬†Build, Artifact¬†Registry, Logging, Monitoring. |
| 5   | Sets gcloud defaults so you don‚Äôt repeat flags. |
| 6   | Creates a private Docker repo in Artifact¬†Registry. |
| 7   | Cloud¬†Build builds the Dockerfile and pushes the image. |
| 8   | Deploys the container to Cloud¬†Run with 0¬†‚Üí¬†3 autoscaling instances. |
| 9   | Prints the public HTTPS endpoint. |

After deployment, test:
```bash
curl "$RAG_URL/rag?question=What+is+this+service%3F"
```

---

## ‚öôÔ∏è¬†Tunable settings

| Constant      | Default | Why it matters |
|---------------|---------|----------------|
| `CHUNK_SIZE`  | 800 chars | Coherence vs. recall |
| `K`           | 8 chunks | Context depth vs. prompt size |
| `MAX_TOKENS`  | 256 | Response length (provider limits vary) |
| `EMBED_MODEL` | MiniLM-L6-v2 | Swap for higher accuracy / slower speed |
| `VECTOR_PATH` | `./faiss_index` | Where FAISS index is persisted |

---

## üóÇÔ∏è¬†Project structure
```
.
‚îú‚îÄ‚îÄ rag_demo_fastapi.py   # FastAPI + LangChain application
‚îú‚îÄ‚îÄ Dockerfile            # container definition (see docs)
‚îú‚îÄ‚îÄ cloudbuild.yaml       # optional CI/CD pipeline
‚îú‚îÄ‚îÄ documents/            # ‚Üê put your knowledge base here
‚îú‚îÄ‚îÄ faiss_index/          # auto‚Äëgenerated FAISS files
‚îî‚îÄ‚îÄ README.md             # you are here
```

---

## üìú License & credits

* Code: MIT
* gpt4free: ¬©¬†xtekky (GPL‚Äë3) ‚Äî use responsibly
* Sentence‚Äëtransformers & FAISS: Apache‚Äë2.0

> Built with ‚ù§Ô∏è using FastAPI, LangChain, and a pinch of guerrilla GPT‚Äë4 power.
